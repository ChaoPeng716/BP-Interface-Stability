{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D-MPNN training for Eint_H2O prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('.')\n",
    "\n",
    "from mpnn_model import DataManager, MPNNTrainer, MPNNHyperparameterOptimizer\n",
    "from chemprop import nn\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = pd.read_csv('dataset_Eint_H2O.csv', index_col=0)\n",
    "print(f\"Data loaded successfully! Shape: {df_input.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df_input.head())\n",
    "\n",
    "print(\"\\nColumn names:\")\n",
    "print(df_input.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = 'Eint_H2O'\n",
    "SMILES_COLUMN = 'CanonSMILES'\n",
    "CLASS_COLUMN = 'Class_label'\n",
    "\n",
    "print(\"Initializing DataManager...\")\n",
    "data_manager = DataManager(\n",
    "    df_input=df_input,\n",
    "    target_label=TARGET_COLUMN,\n",
    "    smiles_label=SMILES_COLUMN,\n",
    "    class_label=CLASS_COLUMN,\n",
    "    ratios=(0.8, 0.1, 0.1),  # 80% train, 10% val, 10% test\n",
    "    n_splits_cv=10,    # 1 for final training, 10 for hyperparameter optimization\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "print(f\"Data splitting completed!\")\n",
    "print(f\"Number of CV splits: {data_manager.n_splits_cv}\")\n",
    "print(f\"Test set size: {len(data_manager.test_mol_ids)}\")\n",
    "\n",
    "if data_manager.cv_splits:\n",
    "    train_ids, val_ids = data_manager.cv_splits[0]\n",
    "    print(f\"First fold - Train: {len(train_ids)}, Val: {len(val_ids)}\")\n",
    "\n",
    "    train_classes = df_input.loc[train_ids, CLASS_COLUMN].value_counts()\n",
    "    val_classes = df_input.loc[val_ids, CLASS_COLUMN].value_counts()\n",
    "    test_classes = df_input.loc[data_manager.test_mol_ids, CLASS_COLUMN].value_counts()\n",
    "    \n",
    "    print(\"\\nClass distribution:\")\n",
    "    print(\"Train:\", train_classes.to_dict())\n",
    "    print(\"Val:\", val_classes.to_dict())\n",
    "    print(\"Test:\", test_classes.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model training (for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting data for fold 0...\")\n",
    "train_dset, val_dset = data_manager.get_data_for_fold(0)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dset)}\")\n",
    "\n",
    "model_config = {\n",
    "    \"batch_size\": 16,\n",
    "    \"depth\": 4,\n",
    "    \"message_hidden_dim\": 300,\n",
    "    \"ffn_hidden_dim\": 300,\n",
    "    \"ffn_num_layers\": 3,\n",
    "    \"dropout\": 0.2,\n",
    "    \"max_lr\": 1e-3,\n",
    "    \"init_lr_ratio\": 0.5,\n",
    "    \"final_init_lr_ratio\": 0.001,\n",
    "}\n",
    "\n",
    "# 创建MPNNTrainer\n",
    "print(\"\\nInitializing MPNNTrainer...\")\n",
    "metrics = [nn.metrics.RMSEMetric(), nn.metrics.MAEMetric(), nn.metrics.R2Metric()]\n",
    "\n",
    "trainer = MPNNTrainer(\n",
    "    model_config=model_config,\n",
    "    metrics=metrics,\n",
    "    max_epochs=200,\n",
    "    patience_early_stopping=50,\n",
    "    enable_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "val_loss = trainer.train(train_dset, val_dset)\n",
    "print(f\"Training completed! Final validation loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, val_ids = data_manager.cv_splits[0]\n",
    "test_ids = data_manager.test_mol_ids\n",
    "test_dset, _ = data_manager.get_test_data()\n",
    "\n",
    "datasets_config = [\n",
    "    {'dset': train_dset, 'name': 'Train', 'ids': train_ids},\n",
    "    {'dset': val_dset, 'name': 'Validation', 'ids': val_ids},\n",
    "    {'dset': test_dset, 'name': 'Test', 'ids': test_ids}\n",
    "]\n",
    "\n",
    "results = {}\n",
    "dfs = {}\n",
    "\n",
    "for config in datasets_config:\n",
    "    name = config['name']\n",
    "    dset = config['dset']\n",
    "    ids = config['ids']\n",
    "        \n",
    "    print(f\"\\nEvaluating model on {name} set...\")\n",
    "\n",
    "    df_subset = data_manager.df_input.loc[ids]\n",
    "    targets = df_subset[data_manager.target_label].values\n",
    "    eval_results = trainer.evaluate(dset, targets)\n",
    "    if not eval_results:\n",
    "        continue\n",
    "    \n",
    "    results[name] = {\n",
    "        'eval': eval_results,\n",
    "        'residuals': eval_results[\"true_values\"] - eval_results[\"predictions\"]\n",
    "    }\n",
    "    \n",
    "    dfs[name] = pd.DataFrame({\n",
    "        'y_true': eval_results[\"true_values\"],\n",
    "        'y_pred': eval_results[\"predictions\"]\n",
    "    }, index=ids)\n",
    "\n",
    "if dfs:\n",
    "    with pd.ExcelWriter('evaluation_results.xlsx') as writer:\n",
    "        for name, df in dfs.items():\n",
    "            df.to_excel(writer, sheet_name=f'{name}set')\n",
    "    print(\"\\nSaved evaluation results to Excel file\")\n",
    "\n",
    "\n",
    "if results:\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    colors = {'Train': 'blue', 'Validation': 'green', 'Test': 'orange'}\n",
    "    all_true, all_pred = [], []\n",
    "    \n",
    "    for name, data in results.items():\n",
    "        true_vals = data['eval'][\"true_values\"]\n",
    "        pred_vals = data['eval'][\"predictions\"]\n",
    "        plt.scatter(true_vals, pred_vals, alpha=0.6, \n",
    "                   label=f'{name} Data', color=colors[name])\n",
    "        all_true.extend(true_vals)\n",
    "        all_pred.extend(pred_vals)\n",
    "    \n",
    "    min_val = min(min(all_true), min(all_pred))\n",
    "    max_val = max(max(all_true), max(all_pred))\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'gray', lw=2)\n",
    "    \n",
    "    plt.xlabel(f'True {TARGET_COLUMN}')\n",
    "    plt.ylabel(f'Predicted {TARGET_COLUMN}')\n",
    "    plt.title(f'Predictions vs True Values ({TARGET_COLUMN})')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.5)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nNo data available for plotting predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting hyperparameter optimization...\")\n",
    "\n",
    "hpo_optimizer = MPNNHyperparameterOptimizer(\n",
    "    data_manager=data_manager,\n",
    "    chemprop_metrics=[nn.metrics.RMSEMetric(), nn.metrics.MAEMetric()],\n",
    "    num_samples_tune=10,\n",
    "    max_epochs_per_trial=50,\n",
    "    patience_per_trial=10,\n",
    "    cpus_per_trial=10,\n",
    "    gpus_per_trial=1\n",
    ")\n",
    "hpo_optimizer.run_optimization()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mol_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
